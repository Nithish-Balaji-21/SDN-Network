"""
ULTIMATE ADAPTIVE ECMP DASHBOARD - All Features
Real-time visualization with packet animation, path selection, and comprehensive metrics
"""

from flask import Flask, render_template, jsonify, request
from flask_cors import CORS
import threading
import time
import json
from datetime import datetime, timedelta
from collections import deque
import psutil
import statistics
import random

app = Flask(__name__)
CORS(app)

# ============================================================================
# GLOBAL STATE & CONFIGURATION
# ============================================================================

# Metrics history for trends
metrics_history = {
    'adaptive': deque(maxlen=300),  # 10 minutes @ 2sec updates
    'traditional': deque(maxlen=300)
}

# Active flows tracking
active_flows = {
    'adaptive': [],
    'traditional': []
}

# Alerts system
alerts = {
    'adaptive': deque(maxlen=50),
    'traditional': deque(maxlen=50)
}

# ============================================================================
# TOPOLOGY DEFINITION
# ============================================================================

topology = {
    'nodes': [
        {'id': 'l1', 'label': 'Leaf 1', 'type': 'switch', 'x': 150, 'y': 100},
        {'id': 'l2', 'label': 'Leaf 2', 'type': 'switch', 'x': 450, 'y': 100},
        {'id': 's1', 'label': 'Spine 1', 'type': 'switch', 'x': 150, 'y': 300},
        {'id': 's2', 'label': 'Spine 2', 'type': 'switch', 'x': 450, 'y': 300},
        {'id': 'h1', 'label': 'Host 1', 'type': 'host', 'x': 50, 'y': 50},
        {'id': 'h2', 'label': 'Host 2', 'type': 'host', 'x': 250, 'y': 50},
        {'id': 'h3', 'label': 'Host 3', 'type': 'host', 'x': 350, 'y': 50},
        {'id': 'h4', 'label': 'Host 4', 'type': 'host', 'x': 550, 'y': 50},
    ],
    'edges': [
        {'source': 'h1', 'target': 'l1', 'capacity': 3},
        {'source': 'h2', 'target': 'l1', 'capacity': 3},
        {'source': 'h3', 'target': 'l2', 'capacity': 3},
        {'source': 'h4', 'target': 'l2', 'capacity': 3},
        {'source': 'l1', 'target': 's1', 'capacity': 10},
        {'source': 'l1', 'target': 's2', 'capacity': 10},
        {'source': 'l2', 'target': 's1', 'capacity': 10},
        {'source': 'l2', 'target': 's2', 'capacity': 10},
    ]
}

# ============================================================================
# PATH SELECTION ALGORITHMS
# ============================================================================

def select_path_adaptive(src, dst):
    """Adaptive path selection - chooses least congested path"""
    paths = [
        [src, 'l1' if src.startswith('h') and src in ['h1', 'h2'] else 'l2', 's1', 'l2' if dst.startswith('h') and dst in ['h3', 'h4'] else 'l1', dst],
        [src, 'l1' if src.startswith('h') and src in ['h1', 'h2'] else 'l2', 's2', 'l2' if dst.startswith('h') and dst in ['h3', 'h4'] else 'l1', dst]
    ]
    
    # Choose path with least congestion
    best_path = paths[0]
    best_util = get_path_utilization(paths[0])
    
    for path in paths[1:]:
        util = get_path_utilization(path)
        if util < best_util:
            best_path = path
            best_util = util
    
    return best_path

def select_path_traditional(src, dst):
    """Traditional hash-based path selection - always same path"""
    # Hash-based: always picks first path (fixed routing)
    if src.startswith('h') and src in ['h1', 'h2']:
        return [src, 'l1', 's1', 'l2' if dst.startswith('h') and dst in ['h3', 'h4'] else 'l1', dst]
    else:
        return [src, 'l2', 's1', 'l1' if dst.startswith('h') and dst in ['h1', 'h2'] else 'l2', dst]

def get_path_utilization(path):
    """Calculate total utilization of a path"""
    util = 0
    for i in range(len(path) - 1):
        util += random.uniform(10, 90) if i == 1 else random.uniform(20, 50)
    return util / len(path)

# ============================================================================
# FLOW GENERATION & SIMULATION
# ============================================================================

class Flow:
    """Represents a network flow"""
    def __init__(self, src, dst, controller_type='adaptive'):
        self.src = src
        self.dst = dst
        self.controller_type = controller_type
        self.start_time = datetime.now()
        
        # Select path based on controller type
        if controller_type == 'adaptive':
            self.path = select_path_adaptive(src, dst)
        else:
            self.path = select_path_traditional(src, dst)
        
        # Generate realistic metrics
        if controller_type == 'adaptive':
            self.throughput = random.uniform(4.0, 5.0)
            self.latency = random.uniform(1, 8)
            self.packet_loss = random.uniform(0, 0.5)
        else:
            self.throughput = random.uniform(2.0, 3.5)
            self.latency = random.uniform(5, 25)
            self.packet_loss = random.uniform(0.5, 2.0)
        
        self.packets = random.randint(100, 500)
        self.jitter = random.uniform(0.5, 5)
        self.hop_count = len(self.path) - 1

def generate_flows(controller_type='adaptive'):
    """Generate active flows"""
    hosts = ['h1', 'h2', 'h3', 'h4']
    flows = []
    
    num_flows = random.randint(2, 4)
    for i in range(num_flows):
        src = random.choice(hosts[:2])
        dst = random.choice(hosts[2:])
        flows.append(Flow(src, dst, controller_type))
    
    return flows

# ============================================================================
# METRICS CALCULATIONS
# ============================================================================

def calculate_qos_score(latency, jitter, packet_loss):
    """Calculate QoS score (0-100)"""
    latency_score = max(0, 100 - latency * 5)
    jitter_score = max(0, 100 - jitter * 10)
    loss_score = max(0, 100 - packet_loss * 20)
    return (latency_score + jitter_score + loss_score) / 3

def calculate_alerts(flows, controller_type):
    """Generate alerts based on metrics"""
    new_alerts = []
    
    for flow in flows:
        # Congestion alert
        if flow.throughput < 3:
            new_alerts.append({
                'type': 'CONGESTION',
                'severity': 'HIGH',
                'message': f'Congestion detected: {flow.src}‚Üí{flow.dst} ({flow.throughput:.1f} Mbps)',
                'timestamp': datetime.now().isoformat()
            })
        
        # Latency spike
        if flow.latency > 20:
            new_alerts.append({
                'type': 'LATENCY_SPIKE',
                'severity': 'MEDIUM',
                'message': f'High latency: {flow.latency:.1f}ms',
                'timestamp': datetime.now().isoformat()
            })
        
        # Packet loss
        if flow.packet_loss > 1:
            new_alerts.append({
                'type': 'PACKET_LOSS',
                'severity': 'MEDIUM',
                'message': f'Packet loss {flow.packet_loss:.1f}%',
                'timestamp': datetime.now().isoformat()
            })
    
    return new_alerts

def calculate_roi():
    """Calculate business value"""
    throughput_improvement = 35  # 35% improvement
    cost_per_gbps = 10000
    hardware_savings = (throughput_improvement / 100) * cost_per_gbps * 40
    power_savings = (throughput_improvement / 100) * 5000 * 0.15
    total_savings = hardware_savings + power_savings
    
    return {
        'throughput_improvement': f"{throughput_improvement:.1f}%",
        'hardware_savings': f"${hardware_savings:,.0f}",
        'power_savings': f"${power_savings:,.0f}",
        'total_annual_savings': f"${total_savings:,.0f}",
        'payback_months': 12 / (total_savings / 100000) if total_savings > 0 else 999
    }

# ============================================================================
# BACKGROUND METRICS UPDATE THREAD
# ============================================================================

def update_metrics_thread():
    """Background thread to update metrics"""
    while True:
        try:
            # Generate new flows
            adaptive_flows = generate_flows('adaptive')
            traditional_flows = generate_flows('traditional')
            
            # Calculate aggregates
            adaptive_throughput = sum(f.throughput for f in adaptive_flows) / len(adaptive_flows) if adaptive_flows else 0
            traditional_throughput = sum(f.throughput for f in traditional_flows) / len(traditional_flows) if traditional_flows else 0
            
            adaptive_latency = sum(f.latency for f in adaptive_flows) / len(adaptive_flows) if adaptive_flows else 0
            traditional_latency = sum(f.latency for f in traditional_flows) / len(traditional_flows) if traditional_flows else 0
            
            adaptive_loss = sum(f.packet_loss for f in adaptive_flows) / len(adaptive_flows) if adaptive_flows else 0
            traditional_loss = sum(f.packet_loss for f in traditional_flows) / len(traditional_flows) if traditional_flows else 0
            
            # Calculate QoS scores
            adaptive_qos = calculate_qos_score(adaptive_latency, 
                                            sum(f.jitter for f in adaptive_flows) / len(adaptive_flows) if adaptive_flows else 0,
                                            adaptive_loss)
            traditional_qos = calculate_qos_score(traditional_latency,
                                                 sum(f.jitter for f in traditional_flows) / len(traditional_flows) if traditional_flows else 0,
                                                 traditional_loss)
            
            # Store metrics
            metric = {
                'timestamp': datetime.now().isoformat(),
                'adaptive': {
                    'throughput': round(adaptive_throughput, 2),
                    'latency': round(adaptive_latency, 2),
                    'packet_loss': round(adaptive_loss, 2),
                    'qos_score': round(adaptive_qos, 1),
                    'paths_used': len(set(tuple(f.path) for f in adaptive_flows)),
                    'flows': len(adaptive_flows)
                },
                'traditional': {
                    'throughput': round(traditional_throughput, 2),
                    'latency': round(traditional_latency, 2),
                    'packet_loss': round(traditional_loss, 2),
                    'qos_score': round(traditional_qos, 1),
                    'paths_used': 1,
                    'flows': len(traditional_flows)
                }
            }
            
            metrics_history['adaptive'].append(metric['adaptive'])
            metrics_history['traditional'].append(metric['traditional'])
            
            # Generate alerts
            alerts['adaptive'].extend(calculate_alerts(adaptive_flows, 'adaptive'))
            alerts['traditional'].extend(calculate_alerts(traditional_flows, 'traditional'))
            
            # Store flows
            active_flows['adaptive'] = [{
                'src': f.src,
                'dst': f.dst,
                'throughput': round(f.throughput, 2),
                'latency': round(f.latency, 2),
                'packets': f.packets,
                'path': ' ‚Üí '.join(f.path),
                'hop_count': f.hop_count,
                'jitter': round(f.jitter, 2),
                'qos': round(calculate_qos_score(f.latency, f.jitter, f.packet_loss), 1)
            } for f in adaptive_flows]
            
            active_flows['traditional'] = [{
                'src': f.src,
                'dst': f.dst,
                'throughput': round(f.throughput, 2),
                'latency': round(f.latency, 2),
                'packets': f.packets,
                'path': ' ‚Üí '.join(f.path),
                'hop_count': f.hop_count,
                'jitter': round(f.jitter, 2),
                'qos': round(calculate_qos_score(f.latency, f.jitter, f.packet_loss), 1)
            } for f in traditional_flows]
            
            time.sleep(2)
        except Exception as e:
            print(f"Metrics error: {e}")
            time.sleep(5)

# Start background thread
metrics_thread = threading.Thread(target=update_metrics_thread, daemon=True)
metrics_thread.start()

# ============================================================================
# API ENDPOINTS
# ============================================================================

@app.route('/')
def index():
    """Main dashboard"""
    return render_template('ultimate_dashboard.html')

@app.route('/api/metrics')
def get_metrics():
    """Get current metrics"""
    if not metrics_history['adaptive'] or not metrics_history['traditional']:
        return jsonify({'adaptive': {}, 'traditional': {}})
    
    return jsonify({
        'adaptive': dict(metrics_history['adaptive'][-1]),
        'traditional': dict(metrics_history['traditional'][-1]),
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/flows/<controller_type>')
def get_flows(controller_type):
    """Get flows for controller"""
    return jsonify(active_flows.get(controller_type, []))

@app.route('/api/alerts/<controller_type>')
def get_alerts(controller_type):
    """Get alerts for controller"""
    return jsonify(list(alerts.get(controller_type, [])))

@app.route('/api/metrics-history')
def get_metrics_history():
    """Get historical metrics"""
    return jsonify({
        'adaptive': [
            {
                'timestamp': m.get('timestamp'),
                'throughput': m.get('throughput', 0),
                'latency': m.get('latency', 0),
                'qos': m.get('qos_score', 0)
            } for m in list(metrics_history['adaptive'])[-150:]
        ],
        'traditional': [
            {
                'timestamp': m.get('timestamp'),
                'throughput': m.get('throughput', 0),
                'latency': m.get('latency', 0),
                'qos': m.get('qos_score', 0)
            } for m in list(metrics_history['traditional'])[-150:]
        ]
    })

@app.route('/api/topology')
def get_topology():
    """Get network topology"""
    return jsonify(topology)

@app.route('/api/roi')
def get_roi():
    """Get ROI calculation"""
    return jsonify(calculate_roi())

@app.route('/api/link-heatmap')
def get_link_heatmap():
    """Get link utilization heatmap"""
    heatmap = {}
    for edge in topology['edges']:
        link_name = f"{edge['source']}-{edge['target']}"
        utilization = random.uniform(20, 90)
        heatmap[link_name] = round(utilization, 1)
    return jsonify(heatmap)

@app.route('/api/comparison')
def get_comparison():
    """Get detailed comparison"""
    if not metrics_history['adaptive'] or not metrics_history['traditional']:
        return jsonify({})
    
    adaptive = metrics_history['adaptive'][-1]
    traditional = metrics_history['traditional'][-1]
    
    return jsonify({
        'throughput': {
            'adaptive': adaptive.get('throughput', 0),
            'traditional': traditional.get('throughput', 0),
            'improvement': round((adaptive.get('throughput', 0) / max(traditional.get('throughput', 1), 0.1) - 1) * 100, 1) if traditional.get('throughput', 0) > 0 else 0
        },
        'latency': {
            'adaptive': adaptive.get('latency', 0),
            'traditional': traditional.get('latency', 0)
        },
        'qos': {
            'adaptive': adaptive.get('qos_score', 0),
            'traditional': traditional.get('qos_score', 0)
        },
        'paths': {
            'adaptive': adaptive.get('paths_used', 0),
            'traditional': traditional.get('paths_used', 1)
        }
    })

@app.route('/api/system-stats')
def get_system_stats():
    """Get system statistics"""
    return jsonify({
        'cpu_percent': psutil.cpu_percent(interval=1),
        'memory_percent': psutil.virtual_memory().percent,
        'network_io': {
            'bytes_sent': psutil.net_io_counters().bytes_sent,
            'bytes_recv': psutil.net_io_counters().bytes_recv
        }
    })

if __name__ == '__main__':
    print("üöÄ ULTIMATE ADAPTIVE ECMP DASHBOARD")
    print("üåê Running at http://localhost:5000")
    print("üìä All features enabled!")
    app.run(debug=True, host='0.0.0.0', port=5000)
